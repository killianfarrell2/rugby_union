{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6efb8d51-b079-4b52-9f40-8ec5bad8e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_files(file_folder, match_file, stats_file):\n",
    "\n",
    "    # Read in friendly internationals\n",
    "    all_matches = pd.read_csv(file_folder+match_file)\n",
    "    all_stats = pd.read_csv(file_folder+stats_file)\n",
    "\n",
    "    print('starting games: ',len(all_matches.url))\n",
    "\n",
    "    # Rename url column to key\n",
    "    all_matches = all_matches.rename(columns={\"url\": \"key\"})\n",
    "\n",
    "    # Create key column to join on\n",
    "    all_stats['key'] = all_stats['url'].str.replace('/match-statistics/0', '', regex=False)\n",
    "\n",
    "    # Drop columns\n",
    "    if 'Unnamed: 0' in all_matches.columns:\n",
    "        all_matches = all_matches.drop(columns=['Unnamed: 0'])\n",
    "    if 'Unnamed: 0' in all_stats.columns:\n",
    "        all_stats = all_stats.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    # Filter for data that I need\n",
    "    filtered_rows = all_stats[all_stats['Attribute'].isin(['Tries',\n",
    "                                                       'Conversion Goals',\n",
    "                                                       'Conversion Goal Attempts',\n",
    "                                                        'Penalty Goals',\n",
    "                                                       'Penalty Goal Attempts',\n",
    "                                                        'Dropped Goal Attempts',\n",
    "                                                         'Dropped Goals',\n",
    "                                                      'Metres Run With Ball',\n",
    "                                                       'Yellow Cards',\n",
    "                                                       'Red Cards'])]\n",
    "\n",
    "    # Drop URL columns\n",
    "    filtered_rows = filtered_rows.drop(columns=['url'])\n",
    "\n",
    "    # Create dfs for each attribute\n",
    "    filtered_rows_tries = filtered_rows[filtered_rows['Attribute'] == 'Tries']\n",
    "    filtered_rows_conv = filtered_rows[filtered_rows['Attribute'] == 'Conversion Goals']\n",
    "    filtered_rows_conv_att = filtered_rows[filtered_rows['Attribute'] == 'Conversion Goal Attempts']\n",
    "    filtered_rows_pg = filtered_rows[filtered_rows['Attribute'] == 'Penalty Goals']\n",
    "    filtered_rows_pg_att = filtered_rows[filtered_rows['Attribute'] == 'Penalty Goal Attempts']\n",
    "    filtered_rows_dg = filtered_rows[filtered_rows['Attribute'] ==  'Dropped Goals']\n",
    "    filtered_rows_dg_att = filtered_rows[filtered_rows['Attribute'] == 'Dropped Goal Attempts']\n",
    "\n",
    "    # Drop Attribute Column\n",
    "    filtered_rows_tries = filtered_rows_tries.drop(columns=['Attribute'])\n",
    "    filtered_rows_conv = filtered_rows_conv.drop(columns=['Attribute'])\n",
    "    filtered_rows_conv_att = filtered_rows_conv_att.drop(columns=['Attribute'])\n",
    "    filtered_rows_pg = filtered_rows_pg.drop(columns=['Attribute'])\n",
    "    filtered_rows_pg_att = filtered_rows_pg_att.drop(columns=['Attribute'])\n",
    "    filtered_rows_dg = filtered_rows_dg.drop(columns=['Attribute'])\n",
    "    filtered_rows_dg_att = filtered_rows_dg_att.drop(columns=['Attribute'])\n",
    "\n",
    "    # Rename columns\n",
    "    filtered_rows_tries = filtered_rows_tries.rename(columns={\"Home Result\": \"Home_tries\",\n",
    "                                    \"Away Result\": \"Away_tries\"})\n",
    "    filtered_rows_conv = filtered_rows_conv.rename(columns={\"Home Result\": \"Home_conv\",\n",
    "                                    \"Away Result\": \"Away_conv\"})\n",
    "    filtered_rows_conv_att = filtered_rows_conv_att.rename(columns={\"Home Result\": \"Home_conv_att\",\n",
    "                                    \"Away Result\": \"Away_conv_att\"})\n",
    "    filtered_rows_pg = filtered_rows_pg.rename(columns={\"Home Result\": \"Home_pg\",\n",
    "                                    \"Away Result\": \"Away_pg\"})\n",
    "    filtered_rows_pg_att = filtered_rows_pg_att.rename(columns={\"Home Result\": \"Home_pg_att\",\n",
    "                                    \"Away Result\": \"Away_pg_att\"})\n",
    "    filtered_rows_dg = filtered_rows_dg.rename(columns={\"Home Result\": \"Home_dg\",\n",
    "                                    \"Away Result\": \"Away_dg\"})\n",
    "    filtered_rows_dg_att = filtered_rows_dg_att.rename(columns={\"Home Result\": \"Home_dg_att\",\n",
    "                                    \"Away Result\": \"Away_dg_att\"})\n",
    "\n",
    "\n",
    "    # Now Join back to dataset - keep this as Inner Join\n",
    "    merge_df = pd.merge(all_matches,filtered_rows_tries,\n",
    "                    left_on = 'key', right_on = 'key', how='inner')\n",
    "    merge_df = pd.merge(merge_df,filtered_rows_conv,\n",
    "                    left_on = 'key', right_on = 'key', how='inner')\n",
    "    merge_df = pd.merge(merge_df,filtered_rows_conv_att,\n",
    "                    left_on = 'key', right_on = 'key', how='inner')\n",
    "    merge_df = pd.merge(merge_df,filtered_rows_pg,\n",
    "                    left_on = 'key', right_on = 'key', how='inner')\n",
    "    merge_df = pd.merge(merge_df,filtered_rows_pg_att,\n",
    "                    left_on = 'key', right_on = 'key', how='inner')\n",
    "    merge_df = pd.merge(merge_df,filtered_rows_dg,\n",
    "                    left_on = 'key', right_on = 'key', how='inner')\n",
    "    merge_df = pd.merge(merge_df,filtered_rows_dg_att,\n",
    "                    left_on = 'key', right_on = 'key', how='inner')\n",
    "\n",
    "    print('final games: ',len(merge_df.key))\n",
    "\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9ab303b-cc8b-4955-b10d-c7fbbb7ca1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting games:  84\n",
      "final games:  25\n",
      "starting games:  15\n",
      "final games:  15\n",
      "starting games:  12\n",
      "final games:  12\n",
      "starting games:  11\n",
      "final games:  0\n",
      "starting games:  54\n",
      "final games:  48\n"
     ]
    }
   ],
   "source": [
    "# Set folder\n",
    "set_folder = 'C:/Users/killi/KF_Repo/PGA_Golf/Python_Scripts/Rugby_Union/1_Scrape_Data/Data/'\n",
    "\n",
    "\n",
    "internationals_formatted = format_files(set_folder,'flashscore_internationals_2024.csv', \n",
    "                                        'flashscore_internationals_2024_all_stats.csv')\n",
    "six_nations_formatted = format_files(set_folder,'flashscore_six_nations_2024.csv', \n",
    "                                     'flashscore_six_nations_2024_all_stats.csv')\n",
    "\n",
    "rugby_championship_formatted = format_files(set_folder,'flashscore_rugby_championship_2024.csv', \n",
    "                                     'flashscore_rugby_championship_2024_all_stats.csv')\n",
    "\n",
    "pacifc_nations_formatted = format_files(set_folder,'flashscore_pacific_nations_2024.csv', \n",
    "                                     'flashscore_pacific_nations_2024_all_stats.csv')\n",
    "\n",
    "world_cup_formatted = format_files(set_folder,'flashscore_world_cup_2023.csv', \n",
    "                                     'flashscore_world_cup_2023_all_stats.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2190abc6-1e46-42f5-994a-cee1f956d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the missing files from world cup\n",
    "\n",
    "file = 'flashscore_world_cup_2023.csv'\n",
    "orig_file = pd.read_csv(file_folder+file)\n",
    "# Rename url column to key\n",
    "orig_file = orig_file.rename(columns={\"url\": \"key\"})\n",
    "\n",
    "# These files are from the world cup qualification so can be ignored\n",
    "world_cup_missing = orig_file[~orig_file['key'].isin(world_cup_formatted['key'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed35eb92-ba1f-4fc3-b89a-4757df2db41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of games that we need to gather statistics from\n",
    "\n",
    "file = 'flashscore_pacific_nations_2024.csv'\n",
    "orig_file = pd.read_csv(file_folder+file)\n",
    "# Rename url column to key\n",
    "orig_file = orig_file.rename(columns={\"url\": \"key\"})\n",
    "\n",
    "# These files are from the world cup qualification so can be ignored\n",
    "pacific_missing = orig_file\n",
    "\n",
    "# Find international missing\n",
    "\n",
    "file = 'flashscore_internationals_2024.csv'\n",
    "orig_file = pd.read_csv(file_folder+file)\n",
    "# Rename url column to key\n",
    "orig_file = orig_file.rename(columns={\"url\": \"key\"})\n",
    "\n",
    "# Find international missing\n",
    "international_missing = orig_file[~orig_file['key'].isin(internationals_formatted['key'])]\n",
    "\n",
    "# Combine missing games\n",
    "all_missing = pd.concat([pacific_missing,international_missing],axis=0, ignore_index=True )\n",
    "\n",
    "# Save as csv\n",
    "all_missing.to_csv('all_missing.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28689439-26d8-4d29-82b0-3f9e07133a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Function to convert the date format with the given year\n",
    "def convert_date(date_str, year):\n",
    "    # Add the year to the date string and convert to datetime\n",
    "    return pd.to_datetime(f'{year}.' + date_str.split('.')[0] + '.' + date_str.split('.')[1], format='%Y.%d.%m')\n",
    "\n",
    "\n",
    "# Apply the function to the 'date' column and pass the year as an argument\n",
    "world_cup_formatted['date_2'] = world_cup_formatted['date'].apply(lambda x: convert_date(x, 2023))\n",
    "internationals_formatted['date_2'] = internationals_formatted['date'].apply(lambda x: convert_date(x, 2024))\n",
    "six_nations_formatted['date_2'] = six_nations_formatted['date'] .apply(lambda x: convert_date(x, 2024))\n",
    "rugby_championship_formatted['date_2'] = rugby_championship_formatted['date'].apply(lambda x: convert_date(x, 2024))\n",
    "\n",
    "# Combine the data that we do have \n",
    "\n",
    "all_have_statistics = pd.concat([internationals_formatted,six_nations_formatted,\n",
    "                                 rugby_championship_formatted,world_cup_formatted])\n",
    "\n",
    "print(len(all_have_statistics))\n",
    "\n",
    "# Save as csv\n",
    "all_have_statistics.to_csv('all_have_statistics.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
